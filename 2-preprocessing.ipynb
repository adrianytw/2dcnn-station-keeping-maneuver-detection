{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_hdf('sat-data.h5')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {\n",
    "    \"NORAD_CAT_ID\": \"object\",\n",
    "    \"EPOCH\": \"datetime64\",\n",
    "    \"SEMIMAJOR_AXIS\": \"float64\",\n",
    "    \"ECCENTRICITY\": \"float64\",\n",
    "    \"INCLINATION\": \"float64\",\n",
    "    \"RA_OF_ASC_NODE\": \"float64\",\n",
    "    \"ARG_OF_PERICENTER\": \"float64\",\n",
    "    \"MEAN_ANOMALY\": \"float64\"\n",
    "}\n",
    "\n",
    "# Convert columns using the dictionary\n",
    "df = df.astype(convert_dict, errors='ignore')\n",
    "\n",
    "# Print the data types of all columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['NORAD_CAT_ID'] == '8832']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_by_date(\n",
    "    data: pd.DataFrame,\n",
    "    group_by_id_col: str,\n",
    "    date_col: str,\n",
    "    sort_ascending: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Deduplicates data by keeping the most recent entry for each group based on date.\n",
    "\n",
    "    Args:\n",
    "        data: A pandas DataFrame containing the data.\n",
    "        group_by_id_col: The column to group the data by (e.g., satellite ID).\n",
    "        date_col: The column containing the date information for sorting and deduplication.\n",
    "        sort_ascending: Whether to sort in ascending order (False for most recent first).\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the deduplicated data (copy of the input).\n",
    "    \"\"\"\n",
    "\n",
    "    # Operate on a copy to avoid modifying original data\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    # Extract the date part from the date column (assuming format YYYY-MM-DD)\n",
    "    data_copy['date'] = pd.to_datetime(data_copy[date_col]).dt.date\n",
    "\n",
    "    return (\n",
    "        data_copy.groupby([group_by_id_col, 'date'])\n",
    "        .apply(lambda x: x.sort_values(date_col, ascending=sort_ascending).head(1))\n",
    "        .drop(columns='date')\n",
    "        .reset_index(drop=True)  # Restructure for consistency\n",
    "    )\n",
    "\n",
    "# Example usage\n",
    "deduplicated_data = deduplicate_by_date(df.copy(), 'NORAD_CAT_ID', 'EPOCH', sort_ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_data[deduplicated_data['NORAD_CAT_ID'] == '8832']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_by_ws(data: pd.DataFrame, w: int = 20, step: int = 1) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Reshapes time series data into segments using the Windowing Sliding (WS) method.\n",
    "\n",
    "  Args:\n",
    "    data: A pandas DataFrame containing the time series data with columns:\n",
    "      - NORAD_CAT_ID: The NORAD Catalog ID (string).\n",
    "      - EPOCH: The epoch time (datetime).\n",
    "      - SEMIMAJOR_AXIS, ECCENTRICITY, INCLINATION, RA_OF_ASC_NODE, ARG_OF_PERICENTER, MEAN_ANOMALY: Orbital elements (numerical).\n",
    "    w: The slicing width (window size) of each segment.\n",
    "    step: The slicing step length for the window sliding (default=1).\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame containing the reshaped data with segments as rows. Each segment\n",
    "    contains columns for NORAD_CAT_ID, all orbital elements, and a segment ID.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the slicing width (w) is less than 1.\n",
    "  \"\"\"\n",
    "\n",
    "  if w < 1:\n",
    "      raise ValueError(\"Slicing width (w) must be greater than or equal to 1\")\n",
    "\n",
    "  def segment_data(group):\n",
    "    \"\"\"Segments data for a single NORAD_CAT_ID group.\"\"\"\n",
    "    # Sort by epoch (ensure data is ordered chronologically)\n",
    "    group = group.sort_values(by='EPOCH')\n",
    "\n",
    "    n = len(group)\n",
    "    # Calculate number of segments (s) using integer division\n",
    "    s = n // w\n",
    "\n",
    "    # Create list to store segments with segment ID\n",
    "    segments = []\n",
    "    for i in range(s):\n",
    "      start_idx = i * step\n",
    "      end_idx = min(start_idx + w, n)\n",
    "\n",
    "      # Extract segment data and create segment ID\n",
    "      segment_id = i\n",
    "      segment = group[['NORAD_CAT_ID'] + list(group.columns[1:])].iloc[start_idx:end_idx]\n",
    "      segment['segment_id'] = segment_id\n",
    "\n",
    "      segments.append(segment)\n",
    "\n",
    "    segment.groupby('segment_id')\n",
    "    \n",
    "    return pd.concat(segments)\n",
    "\n",
    "  # 1. Group data by NORAD_CAT_ID\n",
    "  grouped_data = data.groupby('NORAD_CAT_ID')\n",
    "  # 1.1. Filter groups with less than window size (w) data points\n",
    "  filtered_data = grouped_data.filter(lambda x: len(x) >= w)\n",
    "\n",
    "  # 2. group the filtered data\n",
    "  grouped_filtered_data = filtered_data.groupby('NORAD_CAT_ID')\n",
    "  # 3. Apply segment_data function to each filtered group, grouping by segment ID\n",
    "  reshaped_data = grouped_filtered_data.apply(segment_data).reset_index(drop=True)\n",
    "\n",
    "  # drop segment_id column\n",
    "  return reshaped_data\n",
    "\n",
    "reshaped_data = reshape_by_ws(deduplicated_data, w=5, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Normalizes the segment_vector column in a DataFrame using z-score normalization.\n",
    "\n",
    "  Args:\n",
    "    data: A pandas DataFrame containing columns:\n",
    "      - segment_id: The segment ID (string).\n",
    "      - segment_vector: A vector containing the six orbital elements (numpy array).\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame with the same columns but the segment_vector normalized.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get the segment vectors\n",
    "  segment_vectors = data[['SEMIMAJOR_AXIS', 'ECCENTRICITY', 'INCLINATION', 'RA_OF_ASC_NODE', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY']]\n",
    "\n",
    "  # Normalize each vector using z-score (mean 0, standard deviation 1)\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  scaler = StandardScaler()\n",
    "  normalized_vectors = scaler.fit_transform(segment_vectors)\n",
    "  normalized_vectors = pd.DataFrame(normalized_vectors, columns=segment_vectors.columns)\n",
    "  print(normalized_vectors)\n",
    "\n",
    "  # Replace the segment_vector column with the normalized vectors\n",
    "  # data = data.join(normalized_vectors[normalized_vectors.columns.difference(data.columns)])\n",
    "  data = pd.concat([normalized_vectors, data[data.columns.difference(normalized_vectors.columns)]], axis=1)\n",
    "\n",
    "\n",
    "  return data\n",
    "\n",
    "normalized_data = normalize_data(reshaped_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Labels data segments with one-hot encoded maneuver categories based on NORAD_CAT_ID.\n",
    "\n",
    "  Args:\n",
    "    data: A pandas DataFrame containing columns:\n",
    "      - NORAD_CAT_ID: The NORAD Catalog ID (string).\n",
    "      - segment_id: The segment ID (string).\n",
    "      - segment_vector: A vector containing the six normalized orbital elements (numpy array).\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame with additional columns:\n",
    "      - maneuver_category: The maneuver category string (e.g., \"EW\").\n",
    "      - maneuver_label: The one-hot encoded maneuver category (list of 3 integers).\n",
    "  \"\"\"\n",
    "  # import json\n",
    "  # Load the maneuver categories from a JSON file\n",
    "  with open('category-map.json', 'r') as f:\n",
    "    MANEUVER_CATEGORIES = json.load(f)\n",
    "  cat_to_np = {\n",
    "    \"EW\": np.array([1, 0, 0]),\n",
    "    \"EW-NS\": np.array([0, 1, 0]),\n",
    "    \"NM\": np.array([0, 0, 1]),\n",
    "  }\n",
    "  category_map = {}\n",
    "  \n",
    "  for key, value in MANEUVER_CATEGORIES.items():\n",
    "    for cat_id in value:\n",
    "      category_map[cat_id] = cat_to_np[key]\n",
    "    \n",
    "  # Assuming you have a function (or external data) to get maneuver categories by NORAD_CAT_ID\n",
    "  def get_maneuver_category(cat_id):\n",
    "\n",
    "\n",
    "\n",
    "    return category_map.get(cat_id, 'Unknown')\n",
    "\n",
    "  data['maneuver_category'] = data['NORAD_CAT_ID'].apply(get_maneuver_category)\n",
    "\n",
    "  return data\n",
    "\n",
    "labeled_data = label_data(normalized_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data[(labeled_data['NORAD_CAT_ID'] == '8832') & (labeled_data['segment_id'] == 0)].drop(columns=['NORAD_CAT_ID', 'segment_id', 'maneuver_category']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = labeled_data\n",
    "fnp = []\n",
    "fnpy = []\n",
    "# fnp = np.array([])\n",
    "id_list = fdf['NORAD_CAT_ID'].unique()\n",
    "\n",
    "\n",
    "for id in id_list:\n",
    "    fdf[fdf['NORAD_CAT_ID'] == id]\n",
    "    segment_list = fdf[fdf['NORAD_CAT_ID'] == id]['segment_id'].unique()\n",
    "    for segment in segment_list:\n",
    "        fnp.append(fdf[(fdf['NORAD_CAT_ID'] == id) & (fdf['segment_id'] == segment)].drop(columns=['NORAD_CAT_ID', 'segment_id', 'maneuver_category', 'EPOCH']).to_numpy())\n",
    "        fnpy.append(fdf[(fdf['NORAD_CAT_ID'] == id) & (fdf['segment_id'] == segment)]['maneuver_category'].to_numpy() )\n",
    "        print(fdf[(fdf['NORAD_CAT_ID'] == id) & (fdf['segment_id'] == segment)]['maneuver_category'].to_numpy())\n",
    "        \n",
    "        \n",
    "        # print(fdf[(fdf['NORAD_CAT_ID'] == id) & (fdf['segment_id'] == segment)]['maneuver_category'])\n",
    "        # fnp = np.append(fnp, fdf[(fdf['NORAD_CAT_ID'] == id) & (fdf['segment_id'] == segment)].drop(columns=['NORAD_CAT_ID', 'segment_id', 'maneuver_category', 'EPOCH']).to_numpy())\n",
    "\n",
    "# print(fnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnp = np.array(fnp)\n",
    "np.save('sat_data.npy', fnp)\n",
    "fnpy = np.array(fnpy)\n",
    "np.save('sat-labels.npy', fnpy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
