{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"sat-data.h5\"\n",
    "# sat_data = pd.read_hdf(file)\n",
    "filex = \"sat-data.npy\"\n",
    "filey = \"sat-labels.npy\"\n",
    "\n",
    "sat_data = np.load( filex )\n",
    "sat_labels = np.load( filey, allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_data = sat_data.astype('float32')\n",
    "sat_labels = np.array([label[0] for label in sat_labels]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sat_data, sat_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_nn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (127, 4, 128)             1664      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (127, 3, 128)             32896     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (127, 1, 128)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (127, 128)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (127, 192)                24768     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (127, 89)                 17177     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (127, 3)                  270       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76775 (299.90 KB)\n",
      "Trainable params: 76775 (299.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Softmax, Conv1D, MaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "class SequentialNN(tf.keras.models.Sequential):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred_probs = super().predict(x)\n",
    "        rounded_probs = tf.math.round(pred_probs)\n",
    "        predictions = tf.cast(rounded_probs, tf.int32).numpy()\n",
    "        return predictions.flatten()\n",
    "    \n",
    "# Define the CNN model\n",
    "model = SequentialNN()\n",
    "\n",
    "# input_shape = (20, 6, 1)\n",
    "# First convolutional layer (assuming 1D data)\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Max pooling layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(units=192, activation='relu'))\n",
    "model.add(Dense(units=89, activation='relu'))\n",
    "\n",
    "# Output layer with 3 units for maneuver classification (no maneuver, beginning of maneuver, during maneuver) not float but integer\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# # Output layer with 3 output units for classification, [1, 0, 0], [0, 1, 0], [0, 0, 1] sigmoid activation function\n",
    "# model.add(Dense(units=3, activation='sigmoid'))\n",
    "\n",
    "# Compile the model (loss function and optimizer might be different in the paper)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Implement 10-fold cross-validation (code not shown here, refer to Kera's documentation)\n",
    "model.build(input_shape=sat_data.shape)\n",
    "\n",
    "model.summary()\n",
    "# Train the model (refer to Keras documentation for training with validation sets)\n",
    "# model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 5, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0209 - accuracy: 0.5446 - val_loss: 1.1623 - val_accuracy: 0.1154\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7603 - accuracy: 0.7030 - val_loss: 1.3316 - val_accuracy: 0.1154\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5746 - accuracy: 0.7129 - val_loss: 1.6657 - val_accuracy: 0.1154\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8218 - val_loss: 1.9886 - val_accuracy: 0.5385\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2807 - accuracy: 0.9703 - val_loss: 2.3359 - val_accuracy: 0.6538\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.9802 - val_loss: 3.1340 - val_accuracy: 0.6538\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9802 - val_loss: 3.8266 - val_accuracy: 0.6538\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 4.5456 - val_accuracy: 0.6538\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 5.5647 - val_accuracy: 0.6538\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 6.2933 - val_accuracy: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x312c5fd30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(sat_data, sat_labels, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2987 - accuracy: 0.9291\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# model.evaluate(X_test, y_test)\n",
    "model.evaluate(sat_data, sat_labels)\n",
    "# show trustworthiness of the model\n",
    "\n",
    "\n",
    "# show trustworthiness of the model\n",
    "# model.predict(X_test)\n",
    "model.predict(sat_data[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nairda/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export train and test data\n",
    "np.save(\"train_data.npy\", X_train)\n",
    "np.save(\"train_labels.npy\", y_train)\n",
    "np.save(\"test_data.npy\", X_test)\n",
    "np.save(\"test_labels.npy\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
